{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a53d726-4d7d-4552-a179-3178d7c93fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from convolutional_ar.model import ConvAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31aea51-0c79-45f2-a9bf-13ca5abba5f6",
   "metadata": {},
   "source": [
    "# Convolutional Autoregressive Model\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/ryanhammonds/explorations/master/docs/convolution.png\" width=\"500\" style=\"width: 50%; display: block; margin-left: auto; margin-right: auto;\"/>\n",
    "\n",
    "The weights of a convolution kernel are optimized to best predict the center pixel of each window, $\\mathbf{X}_i$. The weights of the kernel (Fig. 2b) are linked based on distance from the center, e.g. the first three weights, $\\{w_0, w_1, w_2\\}$, correspond to indices in the kernel with distances $\\{1, \\sqrt{2}, 2\\}$ from the center pixel. Convolution is the Frobenius inner product between the image and kernel, optimized to best predict the center pixel, $c_i \\in \\mathbf{X}$.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/ryanhammonds/explorations/master/docs/decimation.png\" width=\"600\" style=\"width: 50%; display: block; margin-left: auto; margin-right: auto;\"/>\n",
    "\n",
    "\n",
    "Multiple convolution kernels are learned to account for various spatial scales in image. This is performed by decimating the image by various factors using the same kernel size, resulting in the kernel expanding by the decimation factor. The above image demonstrates this. Decimating the image by a factor of two results in the kernel expanding as shown in c. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "031422b1-4c1e-44c9-ba6c-92a3d7b976e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/kylberg_rot/'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Image files\u001b[39;00m\n\u001b[32m      2\u001b[39m base_dir = \u001b[33m\"\u001b[39m\u001b[33mdatasets/kylberg_rot/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m f = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m f.sort()\n\u001b[32m      5\u001b[39m f = [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m f \u001b[38;5;28;01mif\u001b[39;00m i.endswith(\u001b[33m'\u001b[39m\u001b[33m.png\u001b[39m\u001b[33m'\u001b[39m)]\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'datasets/kylberg_rot/'"
     ]
    }
   ],
   "source": [
    "# Image files\n",
    "base_dir = \"datasets/kylberg_rot/\"\n",
    "f = os.listdir(base_dir)\n",
    "f.sort()\n",
    "f = [i for i in f if i.endswith('.png')]\n",
    "\n",
    "# Randomly choose rotation angle\n",
    "f_rand = []\n",
    "\n",
    "n_imgs = 4480\n",
    "\n",
    "i_start = 0\n",
    "for i in range(n_imgs):\n",
    "    inds = np.arange(i_start, i_start+12)\n",
    "    \n",
    "    np.random.seed(i)\n",
    "    ind = np.random.choice(inds)\n",
    "    \n",
    "    f_rand.append(f[ind])\n",
    "    i_start += 12\n",
    "\n",
    "# Classes\n",
    "classes = [i.split('-')[0].split('.')[0] for i in f]\n",
    "classes = np.unique(classes)\n",
    "\n",
    "y = np.arange(len(classes))\n",
    "\n",
    "classes = {c:int(i) for c, i in zip(classes, y)}\n",
    "n_classes = len(classes)\n",
    "\n",
    "# Data and labels\n",
    "X = torch.zeros(len(f_rand), 576, 576)\n",
    "y = torch.zeros(len(f_rand))\n",
    "\n",
    "for i in range(len(f_rand)):\n",
    "    X[i] = torchvision.io.read_image(f\"{base_dir}/{f_rand[i]}\")[0]\n",
    "    y[i] = classes[f_rand[i].split('-')[0].split('.')[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e6c26a-7bb2-447c-be94-5329d0844fd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m vectors = []\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m]:\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# Decimate\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     X_sub = \u001b[43mX\u001b[49m[:, ::i, ::i]\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Normalize\u001b[39;00m\n\u001b[32m      9\u001b[39m     X_sub = (X_sub - X_sub.mean(axis=(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)).reshape(\u001b[38;5;28mlen\u001b[39m(X_sub), \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)) / \\\n\u001b[32m     10\u001b[39m         X_sub.std(axis=(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)).reshape(\u001b[38;5;28mlen\u001b[39m(X_sub), \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "vectors = []\n",
    "\n",
    "for i in [1, 2, 3, 4, 5]:\n",
    "\n",
    "    # Decimate\n",
    "    X_sub = X[:, ::i, ::i]\n",
    "\n",
    "    # Normalize\n",
    "    X_sub = (X_sub - X_sub.mean(axis=(1, 2)).reshape(len(X_sub), 1, 1)) / \\\n",
    "        X_sub.std(axis=(1, 2)).reshape(len(X_sub), 1, 1)\n",
    "\n",
    "    # Fit\n",
    "    car = ConvolutionalAR(4, verbose=None, n_epochs=20, lr=0.1, loss_fn=torch.nn.L1Loss(), loss_thresh=0.1)\n",
    "    car.fit(X_sub, progress=lambda i: tqdm(i, total=len(X_sub)))\n",
    "    \n",
    "    vectors.append(car.weight_vector_.numpy())\n",
    "\n",
    "# Save\n",
    "vectors = np.column_stack(vectors)\n",
    "np.save(\"vectors_kylberg.npy\", vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d0c8a4-5284-428c-8d89-c3ce7993e5f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train/test split\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X_train, X_test, y_train, y_test = train_test_split(vectors, \u001b[43my\u001b[49m.numpy(), train_size=\u001b[32m0.9\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Normalize\u001b[39;00m\n\u001b[32m      5\u001b[39m X_train = StandardScaler().fit_transform(X_train)\n",
      "\u001b[31mNameError\u001b[39m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, y.numpy(), train_size=0.9)\n",
    "\n",
    "# Normalize\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "# Fit SVM\n",
    "svc = SVC(C=1e3, probability=True)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy\n",
    "print('Train Accuracy: ', (svc.predict(X_train) == y_train).sum() / len(y_train))\n",
    "print('Test  Accuracy: ', (svc.predict(X_test) == y_test).sum() / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f656b7-55b8-4aa0-adc8-0e817c212599",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RocCurveDisplay\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelBinarizer\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m label_binarizer = LabelBinarizer().fit(\u001b[43my_train\u001b[49m)\n\u001b[32m      7\u001b[39m y_onehot_test = label_binarizer.transform(y_test)\n\u001b[32m      8\u001b[39m y_onehot_test.shape  \u001b[38;5;66;03m# (n_samples, n_classes)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot examples\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "label_binarizer = LabelBinarizer().fit(y_train)\n",
    "\n",
    "y_onehot_test = label_binarizer.transform(y_test)\n",
    "y_onehot_test.shape  # (n_samples, n_classes)\n",
    "\n",
    "y_score = svc.predict_proba(X_test)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=7, figsize=(16, 8), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for c in classes.keys():\n",
    "    i = classes[c]\n",
    "\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test[:, i],\n",
    "        y_score[:, i],\n",
    "        name=f\"{c} vs the rest\",\n",
    "        color=\"darkorange\",\n",
    "        plot_chance_level=True,\n",
    "        ax=axes[i]\n",
    "    )\n",
    "    axes[i].set_ylabel(\"True Positive Rate\")\n",
    "    if i > 20:\n",
    "        axes[i].set_xlabel(\"False Positive Rate\") \n",
    "    else:\n",
    "        axes[i].set_xlabel(\"\")\n",
    "    axes[i].get_legend().remove()\n",
    "    axes[i].set_title(f\"{c}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convolutional_ar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
